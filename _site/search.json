[
  {
    "objectID": "posts/local-news-analysis/index.html",
    "href": "posts/local-news-analysis/index.html",
    "title": "Exploring New Article Posts: Part 1",
    "section": "",
    "text": "Iâ€™ve migrated over to Quarto for the purposes of blogging. This has resulted in a loss of old posts. Therefore, Iâ€™m starting over from scratch with an initial post of articles I scraped from a local news outlet.\n\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(knitr)\n\n\narticle_content <-\n    fread(\"data/local_news_archive.csv\")\n\narticle_content[,\n  article_year := format.Date(ARTICLE_DATE_TIME, \"%Y\")\n]\n\narticle_content[,\n  article_date_time_rounded := format.Date(ARTICLE_DATE_TIME, \"%Y-%m-%d\")\n]\n\n\nArticle Counts\n\narticle_counts_year <-\n  article_content[, \n                .(N = .N),\n                by = \"article_year\"] \n\nWe can start by exploring the number of articles published per year to see whether there are any trends.\nThe earliest year we have is 2004 and the most recent year is, obviously, 2023. The article counts for each year were 1258 and 4533, respectively. This equates to a 260.3% increase in articles published. One likely explanation for this sharp rise is the shift away from print media. In 2004, articles were probably more commonly published in print rather than on the website. Over time, this dynamic changed as print media gave way to digital platforms, leading to the observed increase in article counts.\nThe ensuing plot substantiates the previously mentioned explanation, revealing a discernible upward trend from 2004 to 2015. This trajectory not only persists beyond 2015 but becomes more pronounced.\n\narticle_counts_year |>\n  ggplot(aes(x = article_year,\n             y = N)) +\n  geom_col(colour = \"#557C55\",\n           fill = \"#F2FFE9\") +\n  labs(\n    x = NULL,\n    y = \"Count\",\n    title = \"Article Counts by Year\",\n    subtitle = \"The number of articles published per year has increased. It is important to note that 2023\\n only includes articles up until mid November.\"\n  ) +\n  theme_bw()\n\n\n\n\nLooking at article publications by year offered some insights, but it can be expanded upon by exploring publications at a more granular level. We do that next.\nAs opposed to raw counts, we can look at rolling averages (14 days in this case) for article publications. A rolling average is used to smooth out the trends, which could otherwise be distorted by short-term fluctuations.\nAs we can see from the plot from around 2007 onward, publications throughout the year are relatively stable and rarely exceed 20 publications on average. Other notable points to consider are 2004 and the latter part of 2005/start of 2006. Regarding 2004, it is clear that only articles for part of the year were available and subsequently extracted. As for 2005 and 2006, there isnâ€™t a reason that we can immediately discern that could explain the large fluctuations in counts. We leave this for the next post.\n\narticle_counts_rolling_averages <-\n  article_content[, .(N = .N), by = c(\"article_date_time_rounded\", \"article_year\")] |>\n  _[, rolling_count_avg := frollmean(N, n = 14)]\n\narticle_counts_rolling_averages |>\n  ggplot(aes(x = as.Date(article_date_time_rounded),\n             y = rolling_count_avg)) +\n  geom_line(aes(group = article_year),\n            colour = \"#FA7070\") +\n  labs(x = NULL,\n       y = \"Count\",\n       title = \"14-Day Rolling Average Counts\") +\n  scale_x_date(date_breaks = \"2 months\",\n               date_labels = \"%b\") +\n  theme_bw() +\n  facet_wrap(~article_year,\n             scales = \"free_x\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Cheat Your Way to Rom-Com Mastery: Unleashing Chat-GPT on the Buzzfeed Quiz\n\n\n\n\n\n\n\nGenerative AI\n\n\nBuzzfeed\n\n\n\n\nHow to take advantage of Generative AI to complete a romcom quiz.\n\n\n\n\n\n\nFeb 18, 2024\n\n\nAlex Wainwright\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring New Article Posts: Part 1\n\n\n\n\n\n\n\nanalysis\n\n\ndescriptive statistics\n\n\n\n\nA quick exploration of news articles I scraped.\n\n\n\n\n\n\nDec 10, 2023\n\n\nAlex Wainwright\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/buzzfeed-romcom-quiz/index.html",
    "href": "posts/buzzfeed-romcom-quiz/index.html",
    "title": "Cheat Your Way to Rom-Com Mastery: Unleashing Chat-GPT on the Buzzfeed Quiz",
    "section": "",
    "text": "Romcoms are not my forte so a Buzzfeed quiz to guess film titles based on a bad description is a recipe for disaster. The good thing, however, is that it presents a great use case for taking advantage of Generative AI (e.g., Chat-GPT)."
  },
  {
    "objectID": "posts/buzzfeed-romcom-quiz/index.html#aim",
    "href": "posts/buzzfeed-romcom-quiz/index.html#aim",
    "title": "Cheat Your Way to Rom-Com Mastery: Unleashing Chat-GPT on the Buzzfeed Quiz",
    "section": "Aim",
    "text": "Aim\nNot only do we want to leverage Generative AI to complete the 15 item quiz, but we want to automate the answering of each question. That is, we want to identify each item, extract the bad description, submit this to Chat-GPT, obtain an answer, submit the answer to Buzzfeed, and eventually obtain our final score. Setting this up probably took longer than manually completing the quiz, but letâ€™s gloss over that point."
  },
  {
    "objectID": "posts/buzzfeed-romcom-quiz/index.html#how",
    "href": "posts/buzzfeed-romcom-quiz/index.html#how",
    "title": "Cheat Your Way to Rom-Com Mastery: Unleashing Chat-GPT on the Buzzfeed Quiz",
    "section": "How",
    "text": "How\nFor this project, we use the OpenAI and Playwright packages. The OpenAI package allows us to interact with both the Chat-GPT 3.5 and 4 end-points, for which we submit out bad descriptions to. Playwright will automate our browser interactions to emulate a quiz taker.\nThe steps in the script are as follows:\n\nWe are using a synchronous instance of Playwright, which we direct to the quiz page.\nOn the quiz page, we need to locate the quiz section that contains the 15 items, which is achieved by page.locator(\".question__iRCfm\").all(). This is locating the named class element and returning the list of elements contained within (i.e., the individual quiz items).\nFor each quiz item, we extract the inner text (i.e., the bad description).\nWe then setup Chat-GPT. The prompt used was as follows:\n\nIâ€™m going to give you a description of an actual film. I want you to give me the answer. Provide just the film title, nothing else.\n\nWe are explicitly telling Chat-GPT to just provide the movie title based on the description. Without this, Chat-GPT would provide its reasoning on how it got to this answer, which is irrelevant for our purpose.\nWe extract the Chat-GPT answer, find the answer box for the quiz item, and click guess.\nAt this point, the guess will be correct and we can move on to the next item. In the event the answer is incorrect, the quiz allows us to re-attempt our answer. For this setup, weâ€™re only allowing Chat-GPT to have one attempt at answering the question so we find the I give up! button and click it, leading us onto the next item.\nAfter weâ€™ve answered each item, the quiz will generate our score. We used the Playwright screenshot function to capture the scorecard, which tells us how many items we got correct and how we compared to others.\n\n\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nimport os\nfrom playwright.sync_api import sync_playwright\n\nload_dotenv()\n\nif __name__ == \"__main__\":\n\n    client = OpenAI(\n        api_key=os.environ.get(\"OPEN_AI_KEY\"),\n    )\n\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)\n        page = browser.new_page()\n        page.goto(\n            \"https://www.buzzfeed.com/elizabeth_cotton/rom-com-movies-bad-descriptions-quiz\")\n        \n        question_elements = (\n            page\n            .locator(\".question__iRCfm\")\n            .all()\n        )\n\n        for question_element in question_elements:\n            \n            question_text = (\n                question_element\n                .locator(\".questionTileTitle__NxVlZ\")\n                .inner_text()\n            )\n\n            # Submit Question to Chat-GPT -----------------\n\n            chat_gpt_messages = [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"I'm going to give you a description of an actual film. I want you to give me the answer. Provide just the film title, nothing else.\",\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": question_text\n                },\n            ]\n\n            chat_completion = client.chat.completions.create(\n                messages=chat_gpt_messages,\n                model=\"gpt-3.5-turbo-0125\",\n            )\n\n            chat_gpt_answer = (\n                chat_completion\n                .model_dump()[\"choices\"][0][\"message\"][\"content\"]\n            )\n\n            # Identify Question Answer Box ------\n\n            question_answer = (\n                question_element\n                .get_by_label(\"Your Answer\")\n                .fill(chat_gpt_answer)\n            )\n\n            (\n                question_element\n                .get_by_role(\"button\", name=\"Guess\")\n                .click()\n            )\n\n            give_up_button = (\n                question_element\n                .get_by_role(\"button\", name=\"I give up!\")\n            )\n\n            if give_up_button.is_visible():\n                give_up_button.click()\n\n        \n        (\n            page\n            .locator(\".gradient__R2MwP\")\n            .screenshot(path=\"output/buzzfeed_romcom_decscription_quiz/chat_gpt_3_scorecard.png\")\n        )"
  },
  {
    "objectID": "posts/buzzfeed-romcom-quiz/index.html#results",
    "href": "posts/buzzfeed-romcom-quiz/index.html#results",
    "title": "Cheat Your Way to Rom-Com Mastery: Unleashing Chat-GPT on the Buzzfeed Quiz",
    "section": "Results",
    "text": "Results\nBoth Chat-GPT 3.5 and 4 were tested. Each performed far better than me ðŸ˜…. Moreover, we see that Chat-GPT 4 outperformed 3.5 in identifying romcoms based on bad descriptions alone.\n\n\n\nChat-GPT 3.5 results on the romcom bad description movie quiz. The model performed well with a score of 10 out of 15, which is better than 68% of all other quiz-takers.\n\n\n\n\n\nChat-GPT 4 results on the romcom bad description movie quiz. The model performed well with a score of 12 out of 15, which is better both better than Chat-GPT 3.5 and better than 90% of all other quiz-takers."
  },
  {
    "objectID": "posts/buzzfeed-romcom-quiz/index.html#conclusion",
    "href": "posts/buzzfeed-romcom-quiz/index.html#conclusion",
    "title": "Cheat Your Way to Rom-Com Mastery: Unleashing Chat-GPT on the Buzzfeed Quiz",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the experiment showcases the relative ease with which individuals can leverage Generative AI to essentially cheat on quizzes. While this capability may seem impressive, it poses significant risks, particularly in educational settings where tests and online quizzes are vulnerable to exploitation. Even with Chat-GPT 3.5, which performs admirably in our contrived example despite not matching the capabilities of version 4, the potential for abuse is evident. Moreover, the accessibility of Chat-GPT 3.5, being freely available, exacerbates concerns regarding the integrity of current assessment methods. It underscores the pressing need for robust security measures and ethical considerations to mitigate the misuse of AI technology in educational and other domains."
  }
]